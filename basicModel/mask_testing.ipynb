{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers4rec import tf as tr\n",
    "import tensorflow as tf\n",
    "from transformers4rec.tf.ranking_metric import NDCGAt, RecallAt\n",
    "from transformers4rec.tf.utils import testing_utils as test_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", '../data/')\n",
    "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"../data/sessions_by_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin_standard_lib import Schema\n",
    "# define schema object to pass it to the TabularSeqeunceFeatures class\n",
    "SCHEMA_PATH = os.path.join(INPUT_DATA_DIR, 'schema_test.pb')\n",
    "schema = Schema().from_proto_text(SCHEMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 13:57:14.341879: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def tf_yoochoose_like():\n",
    "    return tr.data.tabular_sequence_testing_data.tf_synthetic_data(\n",
    "    num_rows=100, min_session_length=5, max_session_length=20\n",
    "    )\n",
    "df = tf_yoochoose_like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_masking_inputs():\n",
    "    # fixed parameters for tests\n",
    "    NUM_EXAMPLES = 20\n",
    "    MAX_LEN = 10\n",
    "    PAD_TOKEN = 0\n",
    "    NUM_EXAMPLES = 1000\n",
    "    MAX_CARDINALITY = 100\n",
    "    hidden_dim = 16\n",
    "    features = {}\n",
    "    # generate random tensors for test\n",
    "    features[\"input_tensor\"] = tf.convert_to_tensor(\n",
    "        np.random.uniform(0, 1, (NUM_EXAMPLES, MAX_LEN, hidden_dim))\n",
    "    )\n",
    "    # create sequences\n",
    "    labels = np.random.randint(1, MAX_CARDINALITY, (NUM_EXAMPLES, MAX_LEN))\n",
    "    # replace last 2 items by zeros to mimic padding\n",
    "    labels[:, MAX_LEN - 2 :] = 0\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "    features[\"labels\"] = labels\n",
    "    features[\"padding_idx\"] = PAD_TOKEN\n",
    "    features[\"vocab_size\"] = MAX_CARDINALITY\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_masking_inputs = tf_masking_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_masking_inputs['padding_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test_task_output_shape\n",
    "lm = tr.masking.masking_registry['causal'](padding_idx=tf_masking_inputs[\"padding_idx\"])\n",
    "out = lm(tf_masking_inputs[\"input_tensor\"], tf_masking_inputs[\"labels\"], training=True)\n",
    "assert tf.shape(lm.masked_targets)[0] == tf_masking_inputs[\"input_tensor\"].shape[0]\n",
    "assert tf.shape(lm.masked_targets)[1] == tf_masking_inputs[\"input_tensor\"].shape[1]\n",
    "assert out.shape[2] == tf_masking_inputs[\"input_tensor\"].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4j/6q5w3p6s7zb16_63n6np2z1c0000gr/T/ipykernel_65555/1583197656.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasking_registry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'causal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_masking_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"padding_idx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcopy_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtf_masking_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_tensor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# assert out.shape[2] == tf_masking_inputs[\"input_tensor\"].shape[2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "### test serialization masking\n",
    "lm = tr.masking.masking_registry['causal'](padding_idx=tf_masking_inputs[\"padding_idx\"])\n",
    "copy_layer = test_utils.assert_serialization(lm)\n",
    "assert tf.shape(copy_layer.masked_targets)[0] == tf_masking_inputs[\"input_tensor\"].shape[0]\n",
    "# assert out.shape[2] == tf_masking_inputs[\"input_tensor\"].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 112ms/step - target/binary_classification_task/precision: 0.4800 - target/binary_classification_task/recall: 1.0000 - target/binary_classification_task/binary_accuracy: 0.4800 - target/binary_classification_task/auc: 0.5000 - loss: 0.6934 - regularization_loss: 0.0000e+00 - total_loss: 0.6934\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 110ms/step - target/binary_classification_task/precision: 0.4800 - target/binary_classification_task/recall: 1.0000 - target/binary_classification_task/binary_accuracy: 0.4800 - target/binary_classification_task/auc: 0.5000 - loss: 0.6932 - regularization_loss: 0.0000e+00 - total_loss: 0.6932\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 109ms/step - target/binary_classification_task/precision: 0.0000e+00 - target/binary_classification_task/recall: 0.0000e+00 - target/binary_classification_task/binary_accuracy: 0.5200 - target/binary_classification_task/auc: 0.5000 - loss: 0.6930 - regularization_loss: 0.0000e+00 - total_loss: 0.6930\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 107ms/step - target/binary_classification_task/precision: 0.0000e+00 - target/binary_classification_task/recall: 0.0000e+00 - target/binary_classification_task/binary_accuracy: 0.5200 - target/binary_classification_task/auc: 0.5000 - loss: 0.6928 - regularization_loss: 0.0000e+00 - total_loss: 0.6928\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 132ms/step - target/binary_classification_task/precision: 0.0000e+00 - target/binary_classification_task/recall: 0.0000e+00 - target/binary_classification_task/binary_accuracy: 0.5200 - target/binary_classification_task/auc: 0.5000 - loss: 0.6927 - regularization_loss: 0.0000e+00 - total_loss: 0.6927\n",
      "4/4 [==============================] - 0s 22ms/step - target/binary_classification_task/precision: 0.0000e+00 - target/binary_classification_task/recall: 0.0000e+00 - target/binary_classification_task/binary_accuracy: 0.5156 - target/binary_classification_task/auc: 0.5000 - loss: 0.6930 - regularization_loss: 0.0000e+00 - total_loss: 0.6930\n"
     ]
    }
   ],
   "source": [
    "### test eager + graph modes \n",
    "input_module = tr.TabularSequenceFeatures.from_schema(\n",
    "        schema,\n",
    "        max_sequence_length=20,\n",
    "        continuous_projection=64,\n",
    "        d_output=64,\n",
    "        masking='causal',\n",
    "    )\n",
    "body = tr.SequentialBlock([input_module, tr.MLPBlock([64])])\n",
    "test_utils.assert_body_works_in_model(df, input_module, body, run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test only last item is masked when eval_on_last_item_seq_only\n",
    "lm = tr.masking.masking_registry['causal'](\n",
    "    padding_idx=tf_masking_inputs[\"padding_idx\"], eval_on_last_item_seq_only=True\n",
    ")\n",
    "lm.compute_masked_targets(tf_masking_inputs[\"labels\"], training=False)\n",
    "# get non padded last items\n",
    "non_padded_mask = tf_masking_inputs[\"labels\"] != tf_masking_inputs[\"padding_idx\"]\n",
    "rows_ids = tf.range(tf_masking_inputs[\"labels\"].shape[0], dtype=tf.int64)\n",
    "last_item_sessions = tf.reduce_sum(tf.cast(non_padded_mask, tf.int64), axis=1) - 1\n",
    "indices = tf.concat(\n",
    "    [tf.expand_dims(rows_ids, 1), tf.expand_dims(last_item_sessions, 1)], axis=1\n",
    ")\n",
    "last_labels = tf.gather_nd(tf_masking_inputs[\"labels\"], indices).numpy()\n",
    "# get the last labels from output\n",
    "trgt_pad = lm.masked_targets != tf_masking_inputs[\"padding_idx\"]\n",
    "out_last = tf.boolean_mask(lm.masked_targets, trgt_pad).numpy()\n",
    "\n",
    "# check that only one item is masked for each session\n",
    "assert (\n",
    "    tf.reduce_sum(tf.cast(lm.mask_schema, tf.int32)).numpy()\n",
    "    == tf_masking_inputs[\"input_tensor\"].shape[0]\n",
    ")\n",
    "\n",
    "# check only the last non-paded item is masked\n",
    "assert all(last_labels == out_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test mask all next item for eval\n",
    "lm = tr.masking.masking_registry['causal'](\n",
    "    padding_idx=tf_masking_inputs[\"padding_idx\"],\n",
    "    eval_on_last_item_seq_only=False,\n",
    ")\n",
    "masking_info = lm.compute_masked_targets(tf_masking_inputs[\"labels\"], training=False)\n",
    "# get the labels from output\n",
    "trgt_pad = masking_info.targets != tf_masking_inputs[\"padding_idx\"]\n",
    "labels = masking_info.targets[trgt_pad].numpy()\n",
    "# get non padded items when shifting input sequence\n",
    "shift_inputs = tf_masking_inputs[\"labels\"][:, 1:]\n",
    "non_padded_mask = shift_inputs != tf_masking_inputs[\"padding_idx\"]\n",
    "n_labels_sessions = non_padded_mask.numpy().sum(1)\n",
    "all_labels = tf.boolean_mask(shift_inputs, non_padded_mask).numpy()\n",
    "\n",
    "# check that number of labels per session matches\n",
    "assert all(masking_info.schema.numpy().sum(1) == n_labels_sessions)\n",
    "# check all next items are masked\n",
    "assert all(all_labels == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test at least one item is masked when trained\n",
    "\n",
    "lm = tr.masking.masking_registry['causal'](padding_idx=tf_masking_inputs[\"padding_idx\"])\n",
    "masking_info = lm.compute_masked_targets(tf_masking_inputs[\"labels\"], training=True)\n",
    "trgt_mask = tf.cast(masking_info.targets != tf_masking_inputs[\"padding_idx\"], tf.int32)\n",
    "assert all(tf.reduce_sum(trgt_mask, axis=1).numpy() > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check that not all items are masked when training\n",
    "\n",
    "lm = tr.masking.masking_registry['causal'](padding_idx=tf_masking_inputs[\"padding_idx\"])\n",
    "lm.compute_masked_targets(tf_masking_inputs[\"labels\"], training=True)\n",
    "trgt_mask = lm.masked_targets != tf_masking_inputs[\"padding_idx\"]\n",
    "non_padded_mask = tf_masking_inputs[\"labels\"] != tf_masking_inputs[\"padding_idx\"]\n",
    "assert all(trgt_mask.numpy().sum(axis=1) != non_padded_mask.numpy().sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check number of masked positions equal to number of targets\n",
    "\n",
    "lm = tr.masking.masking_registry['causal'](padding_idx=tf_masking_inputs[\"padding_idx\"])\n",
    "lm.compute_masked_targets(tf_masking_inputs[\"labels\"], training=True)\n",
    "trgt_pad = lm.masked_targets != tf_masking_inputs[\"padding_idx\"]\n",
    "assert lm.mask_schema.numpy().sum() == trgt_pad.numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test only last item is masked when training clm on last item\n",
    "lm = tr.masking.masking_registry[\"causal\"](\n",
    "    padding_idx=tf_masking_inputs[\"padding_idx\"],\n",
    "    train_on_last_item_seq_only=True,\n",
    ")\n",
    "lm.compute_masked_targets(tf_masking_inputs[\"labels\"], training=True)\n",
    "# get non padded last items\n",
    "non_padded_mask = tf_masking_inputs[\"labels\"] != tf_masking_inputs[\"padding_idx\"]\n",
    "rows_ids = tf.range(tf_masking_inputs[\"labels\"].shape[0], dtype=tf.int64)\n",
    "last_item_sessions = tf.reduce_sum(tf.cast(non_padded_mask, tf.int64), axis=1) - 1\n",
    "indices = tf.concat(\n",
    "    [tf.expand_dims(rows_ids, 1), tf.expand_dims(last_item_sessions, 1)], axis=1\n",
    ")\n",
    "last_labels = tf.gather_nd(tf_masking_inputs[\"labels\"], indices).numpy()\n",
    "# get the last labels from output\n",
    "trgt_pad = lm.masked_targets != tf_masking_inputs[\"padding_idx\"]\n",
    "out_last = tf.boolean_mask(lm.masked_targets, trgt_pad).numpy()\n",
    "\n",
    "# check that only one item is masked for each session\n",
    "assert (\n",
    "    tf.reduce_sum(tf.cast(lm.mask_schema, tf.int32)).numpy()\n",
    "    == tf_masking_inputs[\"input_tensor\"].shape[0]\n",
    ")\n",
    "\n",
    "# check only the last non-paded item is masked\n",
    "assert all(last_labels == out_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
