{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers4rec import tf as tr\n",
    "import tensorflow as tf\n",
    "from transformers4rec.tf.ranking_metric import NDCGAt, RecallAt\n",
    "from transformers4rec.tf.utils import testing_utils as test_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", '../data/')\n",
    "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"../data/sessions_by_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin_standard_lib import Schema\n",
    "# define schema object to pass it to the TabularSeqeunceFeatures class\n",
    "SCHEMA_PATH = os.path.join(INPUT_DATA_DIR, 'schema_test.pb')\n",
    "schema = Schema().from_proto_text(SCHEMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 14:07:01.103452: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def tf_yoochoose_like():\n",
    "    return tr.data.tabular_sequence_testing_data.tf_synthetic_data(\n",
    "    num_rows=100, min_session_length=5, max_session_length=20\n",
    "    )\n",
    "df = tf_yoochoose_like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_masking_inputs():\n",
    "    # fixed parameters for tests\n",
    "    NUM_EXAMPLES = 20\n",
    "    MAX_LEN = 10\n",
    "    PAD_TOKEN = 0\n",
    "    NUM_EXAMPLES = 1000\n",
    "    MAX_CARDINALITY = 100\n",
    "    hidden_dim = 16\n",
    "    features = {}\n",
    "    # generate random tensors for test\n",
    "    features[\"input_tensor\"] = tf.convert_to_tensor(\n",
    "        np.random.uniform(0, 1, (NUM_EXAMPLES, MAX_LEN, hidden_dim))\n",
    "    )\n",
    "    # create sequences\n",
    "    labels = np.random.randint(1, MAX_CARDINALITY, (NUM_EXAMPLES, MAX_LEN))\n",
    "    # replace last 2 items by zeros to mimic padding\n",
    "    labels[:, MAX_LEN - 2 :] = 0\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "    features[\"labels\"] = labels\n",
    "    features[\"padding_idx\"] = PAD_TOKEN\n",
    "    features[\"vocab_size\"] = MAX_CARDINALITY\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_masking_inputs = tf_masking_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tensor': <tf.Tensor: shape=(1000, 10, 16), dtype=float64, numpy=\n",
       " array([[[0.01431019, 0.28938477, 0.47462903, ..., 0.94949935,\n",
       "          0.2554671 , 0.28995679],\n",
       "         [0.35112655, 0.66784172, 0.40659763, ..., 0.11024972,\n",
       "          0.16774864, 0.50167527],\n",
       "         [0.78267262, 0.93375795, 0.19398625, ..., 0.46027355,\n",
       "          0.28415953, 0.14766647],\n",
       "         ...,\n",
       "         [0.20773027, 0.15688596, 0.47617317, ..., 0.63368863,\n",
       "          0.486057  , 0.25837122],\n",
       "         [0.81021811, 0.01800621, 0.70325015, ..., 0.54219969,\n",
       "          0.9969783 , 0.61658851],\n",
       "         [0.76325322, 0.1749273 , 0.35946897, ..., 0.79285905,\n",
       "          0.47163301, 0.70362971]],\n",
       " \n",
       "        [[0.25288281, 0.78916138, 0.6658682 , ..., 0.01169676,\n",
       "          0.86997157, 0.12544535],\n",
       "         [0.84108847, 0.817121  , 0.21151408, ..., 0.47893457,\n",
       "          0.01829097, 0.46402322],\n",
       "         [0.84205325, 0.39426052, 0.18440333, ..., 0.81939748,\n",
       "          0.22822109, 0.83757334],\n",
       "         ...,\n",
       "         [0.60730627, 0.37492419, 0.79587366, ..., 0.81352953,\n",
       "          0.56226404, 0.58783768],\n",
       "         [0.44130967, 0.96997389, 0.81155187, ..., 0.12436863,\n",
       "          0.58751619, 0.68731749],\n",
       "         [0.24933029, 0.77653361, 0.44720374, ..., 0.9153319 ,\n",
       "          0.15077364, 0.84443197]],\n",
       " \n",
       "        [[0.35682559, 0.42750169, 0.89867753, ..., 0.85972382,\n",
       "          0.42728422, 0.37031708],\n",
       "         [0.66330691, 0.94954561, 0.69527838, ..., 0.78323136,\n",
       "          0.00425771, 0.83829774],\n",
       "         [0.26132385, 0.49825376, 0.54734192, ..., 0.99748211,\n",
       "          0.64468563, 0.74223345],\n",
       "         ...,\n",
       "         [0.8310156 , 0.52175494, 0.18187887, ..., 0.09725745,\n",
       "          0.66953094, 0.78288187],\n",
       "         [0.70979525, 0.85802008, 0.17719764, ..., 0.79398623,\n",
       "          0.05520144, 0.78600077],\n",
       "         [0.53537016, 0.26552898, 0.52004079, ..., 0.76005851,\n",
       "          0.94971158, 0.05082794]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.50399557, 0.97233695, 0.32312746, ..., 0.26677619,\n",
       "          0.12887225, 0.72599031],\n",
       "         [0.49827113, 0.03492775, 0.29068814, ..., 0.44712698,\n",
       "          0.8717472 , 0.24594353],\n",
       "         [0.71480215, 0.44296222, 0.63789234, ..., 0.0291844 ,\n",
       "          0.86573085, 0.58639216],\n",
       "         ...,\n",
       "         [0.84314674, 0.43337603, 0.48703688, ..., 0.43912842,\n",
       "          0.46576752, 0.49074858],\n",
       "         [0.262827  , 0.82690481, 0.28795644, ..., 0.41358322,\n",
       "          0.78978546, 0.49960435],\n",
       "         [0.82571876, 0.42210259, 0.28918907, ..., 0.04558492,\n",
       "          0.23008992, 0.87856636]],\n",
       " \n",
       "        [[0.42841921, 0.5308131 , 0.25783003, ..., 0.44652596,\n",
       "          0.20132693, 0.26924343],\n",
       "         [0.10628045, 0.83132296, 0.15060759, ..., 0.41148605,\n",
       "          0.76299914, 0.13750722],\n",
       "         [0.50321379, 0.83867995, 0.77633385, ..., 0.95691623,\n",
       "          0.06973532, 0.31997458],\n",
       "         ...,\n",
       "         [0.79666641, 0.80096171, 0.32783444, ..., 0.14044323,\n",
       "          0.46205394, 0.8046943 ],\n",
       "         [0.57609825, 0.47281018, 0.87958851, ..., 0.52373124,\n",
       "          0.1931553 , 0.92395772],\n",
       "         [0.31665111, 0.86694114, 0.4326825 , ..., 0.11496036,\n",
       "          0.66358415, 0.48485399]],\n",
       " \n",
       "        [[0.02085411, 0.27651356, 0.30585487, ..., 0.55136246,\n",
       "          0.49029952, 0.36177192],\n",
       "         [0.61808816, 0.28021018, 0.08402307, ..., 0.1225887 ,\n",
       "          0.27428597, 0.4136697 ],\n",
       "         [0.99940842, 0.31345613, 0.38159546, ..., 0.33247959,\n",
       "          0.57453005, 0.18730574],\n",
       "         ...,\n",
       "         [0.54834294, 0.50604704, 0.42840218, ..., 0.01901901,\n",
       "          0.11987709, 0.64188983],\n",
       "         [0.25329987, 0.54227313, 0.64692129, ..., 0.70410156,\n",
       "          0.00572787, 0.7508631 ],\n",
       "         [0.64251168, 0.62795379, 0.81232215, ..., 0.83521816,\n",
       "          0.5470852 , 0.57758814]]])>,\n",
       " 'labels': <tf.Tensor: shape=(1000, 10), dtype=int64, numpy=\n",
       " array([[ 5, 83, 94, ..., 44,  0,  0],\n",
       "        [ 9, 62, 12, ..., 56,  0,  0],\n",
       "        [ 5, 13, 48, ..., 74,  0,  0],\n",
       "        ...,\n",
       "        [67, 33, 92, ..., 67,  0,  0],\n",
       "        [82, 49, 85, ...,  2,  0,  0],\n",
       "        [94, 25, 74, ...,  1,  0,  0]])>,\n",
       " 'padding_idx': 0,\n",
       " 'vocab_size': 100}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_masking_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test output shape and masking output of CLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = tr.masking.masking_registry['causal'](padding_idx=tf_masking_inputs[\"padding_idx\"])\n",
    "out = lm(tf_masking_inputs[\"input_tensor\"], tf_masking_inputs[\"labels\"], training=True)\n",
    "assert tf.shape(lm.masked_targets)[0] == tf_masking_inputs[\"input_tensor\"].shape[0]\n",
    "assert tf.shape(lm.masked_targets)[1] == tf_masking_inputs[\"input_tensor\"].shape[1]\n",
    "assert out.shape[2] == tf_masking_inputs[\"input_tensor\"].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 5 83 94 58  6 43 89 44  0  0], shape=(10,), dtype=int64)\n",
      "tf.Tensor([ 9 62 12 60 91  9 88 56  0  0], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(tf_masking_inputs[\"labels\"][0])\n",
    "print(tf_masking_inputs[\"labels\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  0  0  0  0  0 44  0  0  0], shape=(10,), dtype=int32)\n",
      "tf.Tensor([ 0  0  0  0  0  0 56  0  0  0], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(lm.masked_targets[0])\n",
    "print(lm.masked_targets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "causal masking shifts the true values the left by one (can't predict the first label with no information) and then adds a zero vector as a masked item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test output shape and masking output of MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = tr.masking.masking_registry['masked'](padding_idx=tf_masking_inputs[\"padding_idx\"])\n",
    "out = lm(tf_masking_inputs[\"input_tensor\"], tf_masking_inputs[\"labels\"], training=True)\n",
    "assert tf.shape(lm.masked_targets)[0] == tf_masking_inputs[\"input_tensor\"].shape[0]\n",
    "assert tf.shape(lm.masked_targets)[1] == tf_masking_inputs[\"input_tensor\"].shape[1]\n",
    "assert out.shape[2] == tf_masking_inputs[\"input_tensor\"].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 5 83 94 58  6 43 89 44  0  0], shape=(10,), dtype=int64)\n",
      "tf.Tensor([ 9 62 12 60 91  9 88 56  0  0], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(tf_masking_inputs[\"labels\"][0])\n",
    "print(tf_masking_inputs[\"labels\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  0  0  0  6 43  0  0  0  0], shape=(10,), dtype=int32)\n",
      "tf.Tensor([ 0  0  0  0  0  0 88 56  0  0], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(lm.masked_targets[0])\n",
    "print(lm.masked_targets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLM doesn't shift values - just randomly masks items with zeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test class serialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test serialization masking\n",
    "lm = tr.masking.masking_registry['causal'](padding_idx=tf_masking_inputs[\"padding_idx\"])\n",
    "copy_layer = test_utils.assert_serialization(lm)\n",
    "# assert tf.shape(copy_layer.masked_targets)[0] == tf_masking_inputs[\"input_tensor\"].shape[0]\n",
    "# assert out.shape[2] == tf_masking_inputs[\"input_tensor\"].shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def assert_serialization(layer):\n",
    "    copy_layer = layer.from_config(layer.get_config())\n",
    "\n",
    "    assert isinstance(copy_layer, layer.__class__)\n",
    "\n",
    "    return copy_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test eager + graph modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 103ms/step - target/binary_classification_task/precision: 0.4400 - target/binary_classification_task/recall: 0.4231 - target/binary_classification_task/binary_accuracy: 0.4200 - target/binary_classification_task/auc: 0.5000 - loss: 0.6937 - regularization_loss: 0.0000e+00 - total_loss: 0.6937\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 103ms/step - target/binary_classification_task/precision: 0.0000e+00 - target/binary_classification_task/recall: 0.0000e+00 - target/binary_classification_task/binary_accuracy: 0.4800 - target/binary_classification_task/auc: 0.5000 - loss: 0.6934 - regularization_loss: 0.0000e+00 - total_loss: 0.6934\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 103ms/step - target/binary_classification_task/precision: 0.0000e+00 - target/binary_classification_task/recall: 0.0000e+00 - target/binary_classification_task/binary_accuracy: 0.4800 - target/binary_classification_task/auc: 0.5000 - loss: 0.6932 - regularization_loss: 0.0000e+00 - total_loss: 0.6932\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 102ms/step - target/binary_classification_task/precision: 0.5200 - target/binary_classification_task/recall: 1.0000 - target/binary_classification_task/binary_accuracy: 0.5200 - target/binary_classification_task/auc: 0.5000 - loss: 0.6931 - regularization_loss: 0.0000e+00 - total_loss: 0.6931\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 100ms/step - target/binary_classification_task/precision: 0.5200 - target/binary_classification_task/recall: 1.0000 - target/binary_classification_task/binary_accuracy: 0.5200 - target/binary_classification_task/auc: 0.5000 - loss: 0.6929 - regularization_loss: 0.0000e+00 - total_loss: 0.6929\n",
      "4/4 [==============================] - 0s 20ms/step - target/binary_classification_task/precision: 0.5200 - target/binary_classification_task/recall: 1.0000 - target/binary_classification_task/binary_accuracy: 0.5703 - target/binary_classification_task/auc: 0.5000 - loss: 0.6924 - regularization_loss: 0.0000e+00 - total_loss: 0.6924\n"
     ]
    }
   ],
   "source": [
    "### test eager + graph modes \n",
    "input_module = tr.TabularSequenceFeatures.from_schema(\n",
    "        schema,\n",
    "        max_sequence_length=20,\n",
    "        continuous_projection=64,\n",
    "        d_output=64,\n",
    "        masking='causal',\n",
    "    )\n",
    "body = tr.SequentialBlock([input_module, tr.MLPBlock([64])])\n",
    "test_utils.assert_body_works_in_model(df, input_module, body, run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test only last item is masked when eval_on_last_item_seq_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = tr.masking.masking_registry['causal'](\n",
    "    padding_idx=tf_masking_inputs[\"padding_idx\"], eval_on_last_item_seq_only=True\n",
    ")\n",
    "lm.compute_masked_targets(tf_masking_inputs[\"labels\"], training=False)\n",
    "# get non padded last items\n",
    "non_padded_mask = tf_masking_inputs[\"labels\"] != tf_masking_inputs[\"padding_idx\"]\n",
    "rows_ids = tf.range(tf_masking_inputs[\"labels\"].shape[0], dtype=tf.int64)\n",
    "last_item_sessions = tf.reduce_sum(tf.cast(non_padded_mask, tf.int64), axis=1) - 1\n",
    "indices = tf.concat(\n",
    "    [tf.expand_dims(rows_ids, 1), tf.expand_dims(last_item_sessions, 1)], axis=1\n",
    ")\n",
    "last_labels = tf.gather_nd(tf_masking_inputs[\"labels\"], indices).numpy()\n",
    "# get the last labels from output\n",
    "trgt_pad = lm.masked_targets != tf_masking_inputs[\"padding_idx\"]\n",
    "out_last = tf.boolean_mask(lm.masked_targets, trgt_pad).numpy()\n",
    "\n",
    "# check that only one item is masked for each session\n",
    "assert (\n",
    "    tf.reduce_sum(tf.cast(lm.mask_schema, tf.int32)).numpy()\n",
    "    == tf_masking_inputs[\"input_tensor\"].shape[0]\n",
    ")\n",
    "\n",
    "# check only the last non-paded item is masked\n",
    "assert all(last_labels == out_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test mask all next item for eval\n",
    "lm = tr.masking.masking_registry['causal'](\n",
    "    padding_idx=tf_masking_inputs[\"padding_idx\"],\n",
    "    eval_on_last_item_seq_only=False,\n",
    ")\n",
    "masking_info = lm.compute_masked_targets(tf_masking_inputs[\"labels\"], training=False)\n",
    "# get the labels from output\n",
    "trgt_pad = masking_info.targets != tf_masking_inputs[\"padding_idx\"]\n",
    "labels = masking_info.targets[trgt_pad].numpy()\n",
    "# get non padded items when shifting input sequence\n",
    "shift_inputs = tf_masking_inputs[\"labels\"][:, 1:]\n",
    "non_padded_mask = shift_inputs != tf_masking_inputs[\"padding_idx\"]\n",
    "n_labels_sessions = non_padded_mask.numpy().sum(1)\n",
    "all_labels = tf.boolean_mask(shift_inputs, non_padded_mask).numpy()\n",
    "\n",
    "# check that number of labels per session matches\n",
    "assert all(masking_info.schema.numpy().sum(1) == n_labels_sessions)\n",
    "# check all next items are masked\n",
    "assert all(all_labels == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskingInfo(schema=<tf.Tensor: shape=(1000, 10), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False]])>, targets=<tf.Variable 'Variable:0' shape=(None, None) dtype=int32, numpy=\n",
       "array([[37, 72, 34, ...,  0,  0,  0],\n",
       "       [81, 34, 53, ...,  0,  0,  0],\n",
       "       [98, 52, 29, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [24, 78, 71, ...,  0,  0,  0],\n",
       "       [ 8, 11, 61, ...,  0,  0,  0],\n",
       "       [ 1, 80, 53, ...,  0,  0,  0]], dtype=int32)>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masking_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test at least one item is masked when trained\n",
    "\n",
    "lm = tr.masking.masking_registry['causal'](padding_idx=tf_masking_inputs[\"padding_idx\"])\n",
    "masking_info = lm.compute_masked_targets(tf_masking_inputs[\"labels\"], training=True)\n",
    "trgt_mask = tf.cast(masking_info.targets != tf_masking_inputs[\"padding_idx\"], tf.int32)\n",
    "assert all(tf.reduce_sum(trgt_mask, axis=1).numpy() > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check that not all items are masked when training\n",
    "\n",
    "lm = tr.masking.masking_registry['causal'](padding_idx=tf_masking_inputs[\"padding_idx\"])\n",
    "lm.compute_masked_targets(tf_masking_inputs[\"labels\"], training=True)\n",
    "trgt_mask = lm.masked_targets != tf_masking_inputs[\"padding_idx\"]\n",
    "non_padded_mask = tf_masking_inputs[\"labels\"] != tf_masking_inputs[\"padding_idx\"]\n",
    "assert all(trgt_mask.numpy().sum(axis=1) != non_padded_mask.numpy().sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check number of masked positions equal to number of targets\n",
    "\n",
    "lm = tr.masking.masking_registry['causal'](padding_idx=tf_masking_inputs[\"padding_idx\"])\n",
    "lm.compute_masked_targets(tf_masking_inputs[\"labels\"], training=True)\n",
    "trgt_pad = lm.masked_targets != tf_masking_inputs[\"padding_idx\"]\n",
    "assert lm.mask_schema.numpy().sum() == trgt_pad.numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test only last item is masked when training clm on last item\n",
    "lm = tr.masking.masking_registry[\"causal\"](\n",
    "    padding_idx=tf_masking_inputs[\"padding_idx\"],\n",
    "    train_on_last_item_seq_only=True,\n",
    ")\n",
    "lm.compute_masked_targets(tf_masking_inputs[\"labels\"], training=True)\n",
    "# get non padded last items\n",
    "non_padded_mask = tf_masking_inputs[\"labels\"] != tf_masking_inputs[\"padding_idx\"]\n",
    "rows_ids = tf.range(tf_masking_inputs[\"labels\"].shape[0], dtype=tf.int64)\n",
    "last_item_sessions = tf.reduce_sum(tf.cast(non_padded_mask, tf.int64), axis=1) - 1\n",
    "indices = tf.concat(\n",
    "    [tf.expand_dims(rows_ids, 1), tf.expand_dims(last_item_sessions, 1)], axis=1\n",
    ")\n",
    "last_labels = tf.gather_nd(tf_masking_inputs[\"labels\"], indices).numpy()\n",
    "# get the last labels from output\n",
    "trgt_pad = lm.masked_targets != tf_masking_inputs[\"padding_idx\"]\n",
    "out_last = tf.boolean_mask(lm.masked_targets, trgt_pad).numpy()\n",
    "\n",
    "# check that only one item is masked for each session\n",
    "assert (\n",
    "    tf.reduce_sum(tf.cast(lm.mask_schema, tf.int32)).numpy()\n",
    "    == tf_masking_inputs[\"input_tensor\"].shape[0]\n",
    ")\n",
    "\n",
    "# check only the last non-paded item is masked\n",
    "assert all(last_labels == out_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
