{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers4rec import tf as tr\n",
    "import tensorflow as tf\n",
    "from transformers4rec.tf.ranking_metric import NDCGAt, RecallAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", '../data/')\n",
    "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"../data/sessions_by_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin_standard_lib import Schema\n",
    "# define schema object to pass it to the TabularSeqeunceFeatures class\n",
    "SCHEMA_PATH = os.path.join(INPUT_DATA_DIR, 'schema.pb')\n",
    "schema = Schema().from_proto_text(SCHEMA_PATH)\n",
    "schema = schema.select_by_name(['user_session','product_id-list_seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate short integer column dataframe\n",
    "train_paths = os.path.join(OUTPUT_DIR, \"1/train.parquet\")\n",
    "train_df = pd.read_parquet(train_paths)\n",
    "# train_df = train_df[['user_session']]\n",
    "train_df = train_df[:100]\n",
    "train_df = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def iterate_over_df(\n",
    "#     df: pd.DataFrame\n",
    "# ):  \n",
    "#         def caller():\n",
    "#             for i in range(len(df)):\n",
    "#                 df_dictionary = {}\n",
    "#                 for column in df.columns:\n",
    "#                     df_dictionary[column] = df[column][i]\n",
    "#                 yield df_dictionary\n",
    "#         return caller\n",
    "\n",
    "def iterate_over_df(\n",
    "    df: pd.DataFrame\n",
    "):  \n",
    "    def caller():\n",
    "        for _,j in df.iterrows():\n",
    "            yield(j['user_session'],j['product_id-list_seq'])\n",
    "    return caller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ds_from_df(\n",
    "#     df: pd.DataFrame\n",
    "# ):\n",
    "#     output_shape_x = ({\n",
    "#         'user_session':(1,)\n",
    "#     })\n",
    "#     df = tf.data.Dataset.from_generator(\n",
    "#         iterate_over_df(df),\n",
    "#         # output_types=((tf.int32), tf.int32),\n",
    "#         # output_shapes = (output_shape_x, tf.TensorShape([]))\n",
    "#         output_types=(tf.int32),\n",
    "#         output_shapes = (output_shape_x)\n",
    "#     )\n",
    "#     return df\n",
    "def ds_from_df(\n",
    "    df: pd.DataFrame\n",
    "):\n",
    "    output_shape_x = (\n",
    "        tf.TensorShape([]),\n",
    "        tf.TensorShape([None,])\n",
    "    )\n",
    "    df = tf.data.Dataset.from_generator(\n",
    "        iterate_over_df(df),\n",
    "        # output_types=((tf.int32), tf.int32),\n",
    "        # output_shapes = (output_shape_x, tf.TensorShape([]))\n",
    "        output_types=(tf.int32,tf.int32),\n",
    "        output_shapes = (output_shape_x)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 15:20:41.908675: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "df = ds_from_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_dataset(\n",
    "        df,\n",
    "        batch_size: int,\n",
    "):\n",
    "    df = df.shuffle(5)\n",
    "#     df = df.padded_batch(batch_size, padded_shapes = (([20,]),[]), padding_values = ((0),0),drop_remainder=True)\n",
    "    df = df.padded_batch(batch_size, padded_shapes = (([],[20,])), padding_values = ((0,0)),drop_remainder=True)\n",
    "    df = df.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = batch_dataset(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_session': <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([ 163,   58,   39,   24,  169,  104,  204,  180,  212,  208,  250,\n",
      "        278,  190,  299,  328,  281,  327,  455,  406,  203,  405,  464,\n",
      "        472,  476,  348,  579,  485,  460,  716,  731,  625,  697,  752,\n",
      "        734,  805,  753,  824,  681,  845,  732,  847,  791,  853,  851,\n",
      "        878,  921,  960,  963,  985,  919,  986, 1025,  939, 1047,  936,\n",
      "       1159, 1032,  882, 1170, 1168, 1212,  995, 1216, 1244, 1205, 1105,\n",
      "       1304, 1256, 1230, 1308, 1354, 1177, 1322, 1264, 1400, 1357, 1406,\n",
      "       1366, 1388, 1438, 1490, 1380, 1499, 1470, 1565, 1599, 1495, 1402,\n",
      "       1582, 1419, 1687, 1618, 1610, 1693, 1611, 1766, 1689, 1716, 1742,\n",
      "       1670], dtype=int32)>, 'product_id-list_seq': <tf.Tensor: shape=(100, 20), dtype=int32, numpy=\n",
      "array([[ 54343,  91623, 113630, ...,      0,      0,      0],\n",
      "       [   131,    895,  29351, ...,      0,      0,      0],\n",
      "       [  9741,   9519,      0, ...,      0,      0,      0],\n",
      "       ...,\n",
      "       [104550, 104622, 104708, ...,      0,      0,      0],\n",
      "       [ 18779,  18606,  18780, ...,      0,      0,      0],\n",
      "       [  8165,   8158,   8157, ...,      0,      0,      0]], dtype=int32)>}\n"
     ]
    }
   ],
   "source": [
    "batch_dictionary = {}\n",
    "cols = ['user_session','product_id-list_seq']\n",
    "for i in range(len(df_list[0])):\n",
    "    batch_dictionary[cols[i]] = df_list[0][i]\n",
    "print(batch_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = batch_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {\"target\": tf.cast(tf.random.uniform((100,), maxval=2, dtype=tf.int32), tf.float32)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((dataset, targets)).batch(50,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 20\n",
    "inputs = tr.TabularSequenceFeatures.from_schema(\n",
    "    schema,\n",
    "    max_sequence_length = sequence_length,\n",
    "    masking = 'causal'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = tr.SequentialBlock([inputs, tr.MLPBlock([64])])\n",
    "targets = {\"target\": tf.cast(tf.random.uniform((100,), maxval=2, dtype=tf.int32), tf.float32)}\n",
    "model = tr.BinaryClassificationTask(\"target\").to_model(body, inputs)\n",
    "model.compile(optimizer=\"adam\", run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2/2 [==============================] - 0s 54ms/step - target/binary_classification_task/precision: 0.0000e+00 - target/binary_classification_task/recall: 0.0000e+00 - target/binary_classification_task/binary_accuracy: 0.4800 - target/binary_classification_task/auc: 0.5000 - loss: 0.6933 - regularization_loss: 0.0000e+00 - total_loss: 0.6933\n",
      "Epoch 2/3\n",
      "2/2 [==============================] - 0s 45ms/step - target/binary_classification_task/precision: 0.5200 - target/binary_classification_task/recall: 1.0000 - target/binary_classification_task/binary_accuracy: 0.5200 - target/binary_classification_task/auc: 0.5000 - loss: 0.6930 - regularization_loss: 0.0000e+00 - total_loss: 0.6930\n",
      "Epoch 3/3\n",
      "2/2 [==============================] - 0s 46ms/step - target/binary_classification_task/precision: 0.5200 - target/binary_classification_task/recall: 1.0000 - target/binary_classification_task/binary_accuracy: 0.5200 - target/binary_classification_task/auc: 0.5000 - loss: 0.6929 - regularization_loss: 0.0000e+00 - total_loss: 0.6929\n"
     ]
    }
   ],
   "source": [
    "losses = model.fit(dataset,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
